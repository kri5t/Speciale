%\todo{SKAL VAERE HELT KLART AT DET BYGGER PAA SPECIALET}
%If this is not supposed to be used in a real life setting then what is it supposed to be?
%Because price cannot be presented on its own.
%Not always the best result. We have to communicate that.
The previous discussions emphasize the importance of simulating a real life setting when predicting with the artificial neural network. It was important for us to ensure trustworthiness in our results through transparency and day-ahead simulations over an entire year because the purpose of the ANN - as we see it - is to provide the fundamentals for decision making in practice. The results must therefore give a realistic picture of the performance. Many of our findings throughout the thesis can be directly mapped and related to issues that would be relevant for a system using our model for prediction --- such a system is a Decision Support System (DSS) as described in Section~\ref{sec:dssSection}. Our purpose is not to come up with specific ideas for a DSS but rather emphasize the many encountered issues during modelling of the network is directly transferable to the DSS. It puts extra emphasize on why analysis and proper experimentation should be made in the first place. We have found the following to be relevant for the discussion here:

\begin{itemize}
\item It has been established that results of the Artificial Neural Network is directly dependent on the dataset used for training --- the dataset was selected based on an extensive analysis in combination with different strategies and the experiments validating it. The need for explicitly informing about what constituted the dataset (and thereby the result) can be transferred directly to the specific purpose of a Decision Support System, i.e. trust in result is necessary in decision making and must therefore be obtained through transparency of the underlying data and why it is there. 
\item The necessity of performing exhaustive experiments on unseen data has been found to be of utmost importance to establishing a realistic result. The trustworthiness of the Artificial Neural Network is much dependent on the performed experiments because many use cases can exist. The results must be ensured by covering enough scenarios, e.g. it is not feasible to have a DSS that can run into a situation that cannot be handled by the system if it is not explicitly defined. The same applies for trimming which must also be stated. It is again a matter of ensuring trust through transparency.
\end{itemize}

The above points are related to trust and how it can be obtained by the user through explicitly informing about the underlying information and how the result is obtained. The underlying information can be the dataset but also what situations the model is capable of predicting and to what extend. The

\subsubsection{Decision Support System based on ANN}
The ANN as a DSS can not stand on its own; because a single price without any other information (about how this result was reached) is not enough to base a decision on. As we have pointed out in the input parameter discussion in Section \ref{sec:inputParameterDiscussion} and data manipulation discussion in Section \ref{sec:matrixTrimmingDiscussion} the need for transparency, clarification of the result and trustworthiness are just as important as the results when a decision has to be based on a DSS.

Artificial neural networks are to some extend being used as the foundation for a prediction support system \cite{shim2002past}. They present how a decision support system is created in three steps. First step is to analyze the data and the problem at hand. Then find a suitable solution for the problem and the last step is to present the results in a digestible format for the client. In our analysis and experiments we have accounted for the first two steps in creating a decision support system. The last step requires a whole survey on its own and are out of the scope of this thesis. Our goal in this section is to clarify what preconditions must be met before an ANN can be used for decision making and what challenges this introduces.

An ANN conducts an analysis of a specific dataset and returns a result based on this analysis. The dataset used for a prediction can be both comprehensive and complex. Therefore a decision based on an ANN can only be as informed as the underlying dataset. A thorough understanding of both what kind of preprocessing has been applied to the dataset and where the data originates from are required to gain trust in the system as discussed in Section \ref{sec:inputParameterDiscussion} and \ref{sec:matrixTrimmingDiscussion}. Another factor is the insight in how the decision was reached by the system. This calls for transparency and contradicts the black-box nature of artificial neural networks \cite{fromBlackBoxToTransparentBox}. We have in the earlier discussions elaborated on these problems in regard to our own ANN and in comparison to other peoples work in the field. In this section we will elaborate on these concerns and propose solutions to how these goals can be achieved more easily.

\subsection{Trust in the system - the underlying data}
The underlying data of a prediction is what drives the artificial neural network. It is the core of the prediction and without it we have no prediction see (Section \ref{sec:inputParameterDiscussion}). It is important (not just when modelling the ANN) for a potential user to trust the predictions presented by the system. The input data should always be presented together with the output so the user gets an idea of what inputs resulted in what output. The system must communicate the input parameters and their origin at all times. Knowing where things come from and exactly what input parameters constitute a result is the basis for creating trust. As introduced in Section \ref{sec:uncertainInformation} autonomous systems do not always guarantee the best result and the underlying data are important for the best possible result to be obtained. Users might have different preferred sources for the underlying data. Accommodating these needs and building different versions of the system on top of the data from different suppliers will help the system to gain the users trust. Another aspect of the input data and creating trust is the need to know what is accounted for in the prediction. As a simple example consider air density as a substitute for both temperature and consumption in prediction of wind power (discussed in Section \ref{sec:inputParameterDiscussion}). Consumption can be substituted by temperature where air density can reflect temperature due to pressure being close to constant --- the trust is directly influenced by this knowledge because the intuition might look for consumption in that calculation. Furthermore the user of the system has to know what kind of preprocessing the data has undergone before used as input in the ANN. In the discussion about trimming in Section \ref{sec:matrixTrimmingDiscussion} and calculated inputs in Section \ref{sec:calculatedInputDiscussion} we point out how data manipulation and preprocessing can alter the results of the ANN. Knowing what these parameters 


This emphasizes that these kinds of systems are primarily for experts that have prior knowledge in the field and knows (or can easily be introduced to) the benefits or disadvantages of data preprocessing along with input parameter selection.

%\todo{discuss in relation to other texts. Many texts we did not know how to trust because we had no idea of the underlying data and what they used and how they manipulated}

\subsection{Obtaining transparency - Opening the black-box}
We have obtained the best prediction through data manipulation and black box optimization which have been verified through our experiments in Chapter~\ref{ch:experimentalResults}. The network outputs a prediction which in itself could be used as decision support by the traders. The problematic is for the users to know when it can be trusted and why to even trust it. People are not in the habit of blindly trusting everything that is placed in front of them and especially not when it comes to high-risk decisions e.g. trading stocks, buying electricity etc.

Artificial Neural Networks are known to be a black box \cite{fromBlackBoxToTransparentBox} because the only knowledge consist in the input and output but nothing about the internal logic. There is a need for making the black box more transparent by communicating what is happening inside it. This is a field of research related to ANNs where the researchers attempt to open up the artificial neural network to give the user a result that also communicates how the decision was reached. This is called a grey-box and refers to different methods that seek to communicate how the result of an ANN was reached \cite{young2010using}. One of the methods is called decomposition and attempts to map the interconnections, weights and structures of the neural network to give the user a sense of trust and insight in how the result was conducted. Another approach is pedagogical where the inner workings of the neural networks are ignored but instead tries to map the input to the output data thus explaining the relationship between the two. The last method eclectic is a hybrid between the two but is not commonly implemented in practice. We do not want to distinguish between the methods and point out the best one - since we have limited insight in these methods. We just want to emphasize the need for transparency in how the decisions was reached in ANNs and how these methods can help the user understand the inner workings.

\subsection{Presenting uncertain information}
All of the above data has to be communicated to the user. Often the data is uncertain information in the sense that it will always be an estimate of what the real price will be. Even some of the inputs to the ANN are based on forecasts e.g. meteorological factors and demand as discussed in Section \ref{sec:inputParameterDiscussion}. This leaves us with a trail of possible sources of error that has to be communicated to the user. It is important that we do not leave anything out to hide the fact that there are a lot of unknown dynamics in a neural network that we have no control over \cite{young2010using}. We just have to embrace these unknowns and try to enlighten the user in the best possible way. Error visualization is also important when talking about uncertain information. We need to show the user what the average error margins are on the selected configuration.

The handling of spike prices as discussed in Section \ref{sec:matrixTrimmingDiscussion} are another aspect of the data manipulation that has to be communicated to the user. If the dataset has been trimmed we will no longer be able to predict the highest of the prices. So the choice of using trimming has to be up to the user and not something we impose on them.

The importance of how accurate the result has to be are also reflected in the use of the system. If the user only needs to know the trend of the system the accuracy are not as important as how many times we guess the right direction of the curve movement. Also the closer we get to the hour that needs predicting the better the results get see Section \ref{sec:stepAheadForecastingDiscussion} therefore a trader has to be able to accept a larger error margin when a result for the 24th hour is compared to a result for the 4th hour. This just further emphasizes the importance of the knowledge already held by the users of the system and how well educated in it they are. A neural network is highly configurable and has a lot of parameters that can be tweaked to give us the best result. We of course try to communicate the best possible solution in a given scenario. The user needs to have some expert knowledge to know whether this solution seems reasonable in the given situation or if some of the input parameters, network parameters or preprocessing parameters should be tweaked to obtain a better result. Again these tweak-able parameters can be perceived as uncertain information \cite{UncertainInformation} in the sense that they are not quantifiable and we do not know exactly the right combination that will give the best result in a given situation. 

\subsection{Concluding remarks}
In this section we have presented some of the problems and possible downfalls when modeling a DSS around an ANN based on the experiments discussions and the results from the tests. We pointed out that the trust in the system heavily relies on the underlying data and what manipulation have been applied to it. These factors needs to be communicated to the user in a digestible format so that he knows every step taken to reach the final prediction. Along with the information about data manipulation and input parameters the user needs to know what the expected error margins for the predictions are. All of this are included to give the user confidence in the system and allow them to take an informed choice. We also pointed out that transparency and insight in the system can help the user gain trust in the system. This can be achieved by opening the black-box and present to the user how the predictions was reached. We again have to emphasize that these are not answers to how a DSS should be build but preconditions that we think has to be considered when building an ANN. If these preconditions have been accounted we think that an artificial neural network can be used as the foundation for a decision support system.

%The need for presenting uncertain information is presented in~\ref{sec:uncertainInformation}.
%f.x. the difference in accuracy when in the lowest and highest numbers.

%\subsection{How to make DSS a reality!?!?!?!}
%\begin{itemize}
%\item Improve understanding of the underlying data and the output;
%\item Transparency is the goal;
%\item Let the user take decisions based on the uncertain information;
%\item Visualize errors;
%\end{itemize}

%\todo{the success of the predictions in the dss rely heavily on the use.. users are important!}
%\todo{... videregive information og dele. Vores bedste resultat er ikke gaeldende alle steder jvf. 24 timer ahead fra forskellige starting points. Det underliggende bliver noedt til at vaere gjort klart for den, der bruger systemet}