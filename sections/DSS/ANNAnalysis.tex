Our goal is to clarify what preconditions must be met before an artificial neural network can be used for decision making. A neural network conducts an analysis of a dataset and returns a result based on these parameters. The dataset used for a prediction can be both complex and massive(Brug et andet ord). Therefore a decision based on a neural network can only be as informed as the underlying dataset. A thorough understanding of both what kind of preprocessing has been applied to the dataset and where the data originates from are required to gain trust in the system. In this section we will try to elaborate on these concerns and propose solutions to how this is obtained.

\subsection{Obtaining transparency - the underlying data}
The underlying input data is easy to present to the user. It should always be shown together with the output so the user gets an idea of what inputs resulted in what output. The system must communicate the input parameters and their origin at all times. Knowing where things come from and exactly what input parameters constitute a result is the basis for creating trust. As introduced in~\ref{sec:uncertainInformation} autonomous systems do not always guarantee the best result and the underlying data are important for the best possible result to be obtained. Different users  could be implemented so that the users themselves supply the input. This would create an extra layer of security since the input parameters could be checked and validated before letting them into the system. 

\section{Trust in the system}
We have obtained the best possible prediction through data manipulation and black box optimization which have been verified through our experiments in Chapter~\ref{ch:experimentalResults}. The network outputs a prediction which in itself could be used as decision support by the traders. The problematic here is for the users to know when it can be trusted and why to even trust it. People are not in the habit of blindly trusting everything that is placed in front of them and especially not when it comes to high-risk decisions. 
Artificial Neural Networks are known to be a black box \cite{fromBlackBoxToTransparentBox} because the only knowledge consist in the input and output but nothing about the internal logic. There is a need for making the black box more transparent by communicating what is happening inside it. \todo{discuss in relation to other texts. Many texts we did not know how to trust because we had no idea of the underlying data and what they used and how they manipulated}

\subsection{Presenting uncertain information}
The need for presenting uncertain information is presented in~\ref{sec:uncertainInformation}.
f.x. the difference in accuracy when in the lowest and highest numbers.

\subsection{How to make DSS a reality!?!?!?!}
\begin{itemize}
\item Improve understanding of the underlying data and the output;
\item Transparency is the goal;
\item Let the user take decisions based on the uncertain information;
\item Visualize errors;
\end{itemize}

\todo{the success of the predictions in the dss rely heavily on the use.. users are important!}
\todo{... videregive information og dele. Vores bedste resultat er ikke gaeldende alle steder jvf. 24 timer ahead fra forskellige starting points. Det underliggende bliver noedt til at vaere gjort klart for den, der bruger systemet}