The purpose of the black box optimization was to find the best number of epochs and best size of the training set. It showed in both prediction of wind power and electricity price what was expected of it. It revealed that too many or too few number of epochs resulted in an over- or under-fitting of the networks function. Section~\ref{sec:annSection} describes a common pitfall when using Artificial Neural Networks where the generalization function of the network is overfitted. It means that the function of the network only fits the training set and not the data that has not yet been seen, the testing set. The way we have dealt with over-fitting in this thesis is early stopping and dividing the datasets into a training set and a testing set. We tried different epochs from 1-2800 and selected the number of epochs that achieved the best result on the testing set. This gives the best picture because predictions will of course always be done on data that has not been seen before. 

Over- and under-training of the network as presented in\cite{1} was more clear for wind power. Too few  and too large datasets resulted in a significant worsening in the error from 19,7\% to 48,64\% compared to the best size of data at 3 month. The same did not apply for electricity prices where the best size showed to be half a year and where the errors were closer to the best result varying from 3,19\% to 7,19\%. It emphasizes the need for experimenting with the right amount for the specific type of prediction.

The prediction time showed to be almost linear with the training set size in both cases. The times varied from 232 to 844 seconds for electricity prices and 462 to 1585 seconds for wind power. It needs to be said that the times are recorded for an entire year to show that the time can be directly mapped to the training set size. What takes the time is the actual training of the network but from the best to the worst case for wind power in the individual 24-step-ahead predictions there is only a difference between 1,3 ($1585/60 = 4,4$) and 4,4 ($1585/60 = 4,4$) seconds which makes it almost indifferent if it was the case that the bigger set was the better since it is to be used by traders to predict 24-hours-ahead. If it instead was an autonomous algorithm with the purpose of placing bids itself then the time constraint would have a whole other meaning \todo{find ref to stock} which is not the care here.  