The strength of the prediction is very much dependent on the quality of the underlying data. As described in Section~\ref{sec:dataCollection} the data must satisfy certain criteria before it can be used as input and output for the Artificial Neural Network. It must be trustworthy and contain hourly observations for our specific purposes, e.g. day-ahead wind power and electricity price prediction based on a dataset that consists of hourly observations. All calculations in the ANN are based on this data which makes it of utmost importance for the forecast. The selection of the correct input parameters for testing is equally important which is described in the analysis in Chapter~\ref{ch:theANNs}. The analysis of both electricity price and wind production together with Experiment One~\ref{sec:windPowerExperimentOne} and~\ref{sec:priceExperimentOne} show how the combination of the right parameters is the core to a good prediction. It is necessary to make a comprehensive analysis of different parameters to know what to include in the experiment and how to represent them. A good example of this is the seasonal aspect for electricity prices which showed difference in result when used as month or as the specific season (summer, winter, ect.). Consequently, the pre-requisites for the wind power and electricity price experiments to perform accurately is the the quality and selection of the input data since it is the basic foundation for the Artificial Neural Network to generalize upon. The importance of analysing exactly what input parameters constitutes the electricity price and how they are represented is much omitted in\cite{1,ShortTermWindPowerForecasting,singhal2011electricity} which is also discussed in Section~\ref{sec:priceExperimentThree}. It makes it very difficult to imitate the behaviour and use or test their knowledge and experience on how to include and represent inputs in the best possible way. The seasonal aspect can as mentioned be included in different ways, matrix can be used and the combination of the inputs have very different impact. Exactly what combination of inputs and how they are represented should always be documented for others to imitate and test. Our experiments showed that even though some inputs was closely co-related to the output it was not necessarily included in the best prediction as seen with consumption and wind power. It is not enough to simply list the characteristics of the output to predict without mentioning what came out of the analysis, if the experiments validated it and exactly what inputs was used. The focus should not be focused on the results alone but how the result is obtained, especially in the case of input parameters for the neural network which have shown to be of utmost importance in our analysis.  

As described above the different combinations of input parameters is found in experiment one for both electricity prices and wind power production. The experiments show the complexity in the black box nature of ANN since it identifies better connections of input than foreseen. In wind power production the substitution of temperature and air density with consumption showed better accuracy which was not expected, whereas wind speed showed to be much more crucial to the electricity price than foreseen. Wind power production impacts the electricity price as presented in \cite{dayAheadImpactOfWindPowerForecasts} but more than expected. This leads to the potential of feeding the electricity price with the prediction of wind power as input instead of wind speed to make the prediction more accurate. This connection has to be investigated in future work.

The seasonality characteristic of the wind power production and electricity price time-series is in both cases significant and for that reason expected to increase performance for both predictions. Seasonality is reflected in the month input parameter and showed different results. The month parameter obviously decreased the overall performance of the network in the case of wind power whereas it was increased in the electricity price. The first thought was the small size of the data only containing three months and therefore not reflecting the the seasons from the previous year which was the intention. When attempted on a whole years training set it showed an overall worsening in accuracy due to over-training due to the bigger training set. The electricity prices with the seasonal aspect was also tried with a training set containing a year but as opposed to wind power the accuracy of the forecasts stayed the same. What can be concluded from this is that more data is not necessarily equal to better results in both cases and 3 months of data is the most expressive to predict 24 hours ahead. What was believed to be problematic was the shifting from one season to another where the new season was significantly different from the one we came from. This was proven wrong by the experiments since 3 months itself showed to contain enough information about the current season to be accurate and the the potential shortcomings from seasonal shifts were compensated by the omission of unnecessary data from the rest of the year. The high volatility results in many different cases during the year which can make it hard for the network to generalize when the data set becomes to huge.

The wind power section emphasized in connection with input parameter experiments the need for measuring accuracy of results only on the testing set (unseen data). It was seen in Table~\ref{table:predictionMAEUnseenVsTrainingSet} that the MAE could be the same across all predictions on the training set compared to a huge difference when applied on the testing set. The best MAE on unseen data showed the worst MAE on the training set. 