This section is based on information from the book AI techniques for game programming\cite{buckland2002ai} chapter 7, 8 \& 9. Also from the book Neural networks: a systematic introduction\cite{rojas1996neural} chapter 7.
\\[0.5cm]
Neural networks are models that imitate the brains behavior. They have been created as an option to model artificial intelligence and analyze machine learning. The human brain is made up of billions of neurons that are interconnected in a big grid. They communicate by firing electrical shocks through the network of neurons. The human brain is extremely complex and can calculate vast amounts of data in no time. This is why scientists and mathematicians have been trying to emulate this behavior to create artificial intelligence.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\linewidth]{billeder/ANN.png}
\caption{A simple neural network with 3 layers. \cite{stockForecasting}}
\label{fig:ANN}
\end{figure}

Artificial neural networks (ANN) are artificial neurons (nodes) that are connected in a network. The network consists of an arbitrary number of layers that are interconnected. The most common structure in these networks are a feed forward structure. This kind of structure has the characteristic that it only flows data from the input layer through the hidden layers to the output layer. There are no loops in the network thus making it unable to reiterate any information. Normally all of the nodes in the input layer is connected to all of the nodes in the second layer. The same connections are done in the next layers until we hit the output layer. This will give us the sum of all the previous nodes($x_i$) and their weights($w_i$)($\sum_{i=0}^{i=n+1} w_i x_i$) in every node in the next layer. See ~\ref{fig:weight_of_layers}.
\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\linewidth]{billeder/weight_of_layers.png}
\caption{How the weight is calculated from one layer to the next. \cite[P. 251]{buckland2002ai}}
\label{fig:weight_of_layers}
\end{figure}
All of these connections carry a weight that dictates how data flows through the network and reflects the relations between the inputs and the outputs of the network. The inputs of the network should be all the factors that has an influence on the output we want from the network. In our example we would want to input; weather data, temperature, demand, availability etc. \cite{21} to get the price as an output from the network.

Every node in our network contains an activation function. This function, when calculated, tells us whether the artificial neuron should fire or not. That is, if the neuron should transmit the data from the current layer to the next layer. There are a lot of different activation functions. The simplest form is the binary step function which either fires or it does not. This depends on the input and gives us a low threshold of complexity which is good in simple neural networks as the relations between the nodes do not need to be that fine grained. In more complex systems we want activation functions with a broader output range than binary. In many cases a sigmoid function is used as the activation function. This is because of the ''S''-shape which enables it to compute outputs in a non-linear way. The non-linear nature of the sigmoid functions is what makes the neural network able to compute non-trivial problems in reasonable sized networks. The sigmoid function allows the activation functions of the neurons to have a broader range of inputs which will produce an output compared to step activation functions. To be able to calculate a non-trivial problem in these kind of networks we need what is called a training algorithm. This algorithm depicts how the network evolves over time also known as learning. There are two kinds of learning; unsupervised learning and supervised learning.

\subsection{Unsupervised learning}
Unsupervised learning is when we do not have output data for the input data. Instead we have a problem where we want the neural network to try and estimate some behavior relative to a specific task based on some assumptions we have about the system it performs on. It is commonly used with estimation problems like "Cluster Analysis", which in short is an attempt to find matching criterion in data and group the data in clusters. This is often done by exploring the dataset and that is what unsupervised learning is good for. It also works with Artificial Intelligence(AI) that have to explore parts of the (virtual)world. In \cite{buckland2002ai} he explains how an unsupervised learning feed-forward artificial neural network trains itself using a genetic algorithm to keep track of the fitness function of the AI. The fitness function is used to tell the AI if it is doing good or bad according to some requirements established before the experiment. This fitness function is what trains the network. The AI will get a plus score if it encounters what we are looking for and get negative if it hits something that we defined as "wrong". Based on this fitness function it will update the weights of the neural network accordingly to what is most beneficial for the network as a total. After it has been allowed to do a lot of runs it begins to get a sense of what it is exploring and should be able to make better choices for each run.

\subsection{Supervised learning}
Supervised learning are a set of algorithms that use a dataset which contains both the inputs and outputs. This dataset is used to train the neural network to make it able to do calculations on current data and predict the outcome. An example of an algorithm used for supervised learning is the back-propagation algorithm. 
It starts out by randomly assigning weights to all of the connections between the neurons. It then calculates the output of the network and compares it to the expected output. From the comparison of output and expected output it calculates the error margin and adjusts the weights accordingly. This is done for all the hidden layers until we hit the input layer. All of these steps are called an epoch. We will repeat as many epochs as we need until the sum of all the errors are within a given threshold. The name of the algorithm originated from these epochs where it propagates the error backwards in the network. We use Resilient Back-propagation (RPROP) which is based on the traditional back-propagation algorithm as described in \cite{rpropForGeometricDilution,adaptiveRprop}. It is a first-order algorithm better at escaping local minima and at the same time scales linearly to the number of input parameters. In short the the difference is in how the weights are being updated through evaluating the behaviour of the error function. The traditional backpropagation adjust its values based on the actual value of the derivative and since the derivative value decreases exponentially as further it gets from the output layer it will take longer time for the last neurons to learn. In RPROP the derivative sign decide the weight adjustment and not the magnitude of the derivative as with traditional backpropagation. RPROP use the same amount of computational effort but is faster due to the derivative sign evaluation. Furthermore, it is not necessary to define the learning rate or momentum because they are automatically adapted and therefore we avoid spending time on fine-tuning these parameters.

Supervised learning can be thought of as learning with a teacher. As an example we can use the XOR table:

\begin{table}[!ht]
\centering  % used for centering table
\begin{tabular}{c c c} % centered columns (3 columns)
Input \#1 & Input \#2 & Output \\ [0.5ex] % inserts table 
%heading
\hline                  % inserts single horizontal line
0 & 0 & 0  \\ % inserting body of the table
1 & 0 & 1  \\
0 & 1 & 1  \\
1 & 1 & 0 \\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\caption{This training set is very simple yet it illustrates a training set for a supervised learning algorithm very well.} % title of Table
\label{table:xor-table} % is used to refer this table in the text
\end{table}

In this dataset we have both of the inputs and we are given the expected output. This gives the back-propagation algorithm a direction to follow when minimizing the error function of the network. We can do this because we a predicted output that we can compare to the expected output which allows us to predict the direction that the error correction should take to close in on the best possible solution. Also the sigmoid activation function helps us closing in on the target output since the sigmoid function always has a positive derivative which ensures that we will always have a direction to follow\cite[p. 153]{rojas1996neural}. This is because the derivative of the sigmoid function always will point us towards the global minimum of the approached function. If we take a look at ~\ref{table:xor-table} we are given inputs and outputs. We take the input 1 and 0 and we expect the output to be 1. The neural network will initialize weights and start to run the back-propagation. The back-propagation algorithm will compare the output it predicts to the output we expected e.g. we may get an output of 0.5 (based on the random weight initialization) and this is compared to the expected output 1. Because of the sigmoid function we know what direction the weights should be corrected to come closer to the output of 1. This allows the back-propagation algorithm to recalculate the weights and be sure that it is heading for the global minimum of the error function thus heading for the right output.
%[FORKLAR MATEMATIKKEN EVT MED EKSEMPEL s. 332 i bogen]

In neural networks bias neurons are often added to the layers to help them learn patterns. The bias neurons are added to give the activation functions the ability to change its output even if x is zero. If we look at the graph in figure ~\ref{fig:activationFunctions} it uses the following activation function: \begin{math} \frac{1}{(1+e^{(-cx)})} \end{math} where c is the weight.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth ,natwidth=410,natheight=237]{billeder/ActivationFunctions.png}
\caption{}
\label{fig:activationFunctions}
\end{figure}

The figure shows how the gradient of the function alters with different weight values. Even though the gradient of the function is clearly altered by the weights the function is still outputting the same result for zero thus we cannot alter the output for x equal to zero just by altering the weights. This is what we use the bias for. If we apply a bias of one to all of the neurons we will be able to shift it either to the left or the right. In figure ~\ref{fig:activationFunctionsWithBias} we see the same function as before where the weight is set to 2. The difference is that we added a bias (b) to this function: \begin{math} \frac{1}{(1+e^{(-2x+b)})} \end{math} \cite[p. 165]{rojas1996neural,inductiveBias}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth ,natwidth=410,natheight=237]{billeder/ActivationFunctionsWithBias.png}
\caption{}
\label{fig:activationFunctionsWithBias}
\end{figure}

\subsection{Common pitfalls}
When we are trying to fit our algorithm and make it recognize patterns we will encounter several possible pitfalls. First of all there is the chance of ending up in a local minima. This is when the the back-propagation algorithm attempts to find the global minimum of the error curve thus having reduced the error as much as possible. The algorithm works by trying to reduce this error margin a little step at a time. If it encounters a local minimum on the curve and thinks it has reached the global minimum it gets stuck and we will get an inaccurate result \ref{fig:localMinimum}. 

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.4\linewidth]{billeder/globalMinimum.png}
  \captionof{figure}{At the global minimum \cite[P. 318]{buckland2002ai}}
  \label{fig:globalMinimum}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.4\linewidth]{billeder/localMinimum.png}
  \captionof{figure}{Stuck in a local minimum \cite[P. 318]{buckland2002ai}}
  \label{fig:localMinimum}
\end{minipage}
\end{figure}

To avoid the backpropagation algorithm to falsely accept a local minimum as the global minimum we can give the algorithm momentum. This is done by adding a bit of the last error correction from the earlier layer to the next layers error correction. This way the algorithm, so to say, will scoot right by any small deviations in the error correction face.
\newline
Another pitfall when working with neural networks is over fitting the algorithm. This is when the algorithm instead of finding a generalized pattern in the inputs it will find an over-fit pattern that will fit exactly the input resulting in problems when presenting the network for unseen data. This is better shown in Figure~\ref{fig:overfitting}.
\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\linewidth,natwidth=1262,natheight=415]{billeder/overfitting.png}
\caption{A. The plot graph of the input B. The generalized function C. An over-fit function \cite[P. 319]{buckland2002ai}}
\label{fig:overfitting}
\end{figure}
This can be avoided by some simple techniques. First of all we want to reduce the neurons as much as possible as long as it does not interfere with our performance of the system (also known as pruning). This is a trial and error problem and has to be tweaked along with evolving the neural network. Another option is to add noise to avoid this problem. By adding noise(random data values) we prevent the algorithm from fitting the function to closely to the given data. Thus giving us a more generalized function where it hopefully will be able to give a better result on unseen data. Early stopping is another method to avoid over-fitting. This is only doable with large datasets where you can split it into two equal datasets. The first will work as a training set and the second will work as a validation set. We will keep training the dataset and checking with the validation set until the difference between those two start to increase.

\subsection{Summary}
This section touched the basics of neural networks and where the inspiration for these networks came from. Feed-forward was presented the most common architecture used for Artificial Neural Networks and  it will also be applied in this thesis. This architecture allows data to only flow from input to output with no loops in it. We elaborated what activation functions are and how they are used in neural networks. Since neural networks are all about the computer learning to calculate some very complex problem we need a learning algorithm. We explained that unsupervised learning algorithms are about exploring possibilities in a space and try to come close to a goal that we set up. It has no definitive goal (opposed to supervised learning) but a success factor that it tries to maximize. We also talked about supervised learning and how these algorithms try to achieve the best possible result. This is done by trial-and-error where the algorithm learns until it satisfies an error margin we chose or for a specific number of epochs. Furthermore we talked about why and what bias is used for. It is a constant that is added to the calculations to prevent the algorithm to stall while trying to find the lowest error margin in our prediction. We also explained common pitfalls and how to avoid these. Among these were over-fitting of the function we are trying to a achieve which means it only fits the training set and not a general set of data. Also we talked about the algorithm falsely believing that the local minimum was the global minimum and therefore coming up with a wrong result.
We also talked about the training set and how this data is handled by the training algorithm. We mainly focus on supervised training since this is what we are gonna use in this thesis. A very important point to make here is that the training set is of utmost importance when it comes to performance and accuracy of our ANN. The training set has to be developed and refined during a training period of a network and relies a lot on experience and tinkering with the inputs. We need to normalize the input set so that it fits each other and all the parameters get the same weighting from the beginning. This is done so that some inputs unintentionally gets a higher significance. Also we can only have assumptions of on which form the inputs will give the best result and we might have to try different forms like numbers, bits, matrices etc. to get the best results.