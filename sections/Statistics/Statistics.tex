This section describes the statistical measures that will be used to determine accuracy of the predictions so that the outputs can be evaluated.

\subsubsection{MPE - Mean Percentage Error}
The \fnurl{Mean Percentage Error}{http://en.wikipedia.org/wiki/Mean_percentage_error} is the mean of the percentage-wise error when comparing the predicted value to the actual value. This value gives us the error in percent relative to the actual value. This is a standard value that a lot of people understand by just looking at it. The problem with this value is that it is relative to the actual value so the same error seen as a number (e.g. 20DKK) will give a big difference if it is close to the minimum values predicted and a small difference if it is close to the maximum values predicted; but in both cases the guess with an error of 20 DKK is equally good (as we see it when attempting to fit the curve). As a mathematical example:
\\[0.5cm]
\noindent Percentage error:
\begin{center}
$\text{\% error} = (\text{estimate} - \text{actual}) / \text{actual} * 100$
\end{center}
\begin{minipage}{\textwidth}
\noindent High values:
\begin{center}
$\text{\% error} = ((1200-1180)/1200)*100 = 1.67\%$
\end{center}
\noindent where $\text{actual} = 1200$ and $\text{estimate} = 1180$
\end{minipage}
\\[0.5cm]
\begin{minipage}{\textwidth}
\noindent Low values: 
\begin{center}
$\text{\% error} = ((60-40)/60) = 33.33\%$
\end{center}
\noindent where $\text{actual} = 60$ and $\text{estimate} = 40$
\\[0.5cm]
\end{minipage}
\noindent If we were to look at the values they are fine; but when we have to compare them they are very different now (even though we just argued they were both equal guesses). This is why we have not included MPE but instead will be using MAPE.
The MPE is calculated by the following:
\begin{center}
$ MPE = \frac{100\%}{n}\sum_{i=1}^{n}\frac{p_i - a_i}{a_i} $
\end{center}
\noindent{Where $p_i$ is the predicted value and $a_i$ is the actual value.}

\subsubsection{MAE - Mean Absolute Error}
\label{sec:maeStatistics}
The \fnurl{Mean Absolute Error}{http://en.wikipedia.org/wiki/Mean_absolute_error} denotes the mean of the differences between the predicted values and the actual values. This gives us an indication of how much the algorithm on average misses the target price as a value and not as a percentage. This value is relative to the dataset and if we increase all our numbers with a factor of 10 so will the MAE thus making it very hard to compare to MAEs between systems. The good thing about the MAE is that it is not a percentage and thus it will not get bigger if the values we predict are low (See MPE - Mean Percentage Error). That way we eliminate the problem with low values giving bigger error margins than high values even when they miss the target by the same value. It is calculated by:

\begin{center}
$MAE = \frac{1}{n}\sum_{i=1}^{n}|p_i-a_i|$
\end{center}

\noindent{where $p_i$ is the predicted value and $a_i$ is the actual value.}
\\[0.5cm]
We see MAE as a better choice because it is related the interval of possible values and thereby an indication of how closely we fitted the curve throughout the dataset. We assume that missing the ideal target by 20 is equally good in both lower and higher numbers, e.g. the example from MPE illustrates this well.

\subsubsection{MAPE - Mean Absolute Percentage Error}
The \fnurl{Mean Absolute Percentage Error}{http://en.wikipedia.org/wiki/Mean_absolute_percentage_error} denotes the difference between the predicted value ($p_i$) and the actual value ($a_i$) which are divided by the median($\tilde{a}$) over the whole dataset. Giving us the following formula:


\begin{center}
$MAPE = \frac{1}{n}\sum_{i=1}^{n}\frac{|p_i-a_i|}{\tilde{a}}$
\end{center}

\noindent Our MAPE is a slightly altered version compared to the standard version. The difference is we use the median instead of the average. We got this version from \cite{yamin2004adaptive} where they argue that the mean value is not as error-prone as the average value is towards extreme outliers. If the dataset either contains a lot of high values or low values the average will be pulled towards them; but the median will always stay in the middle regardless of extreme outliers. This measure is included instead of MPE because it does not have the same errors when comparing high values to low values --- therefore it is a better measure for comparing two experiments.